{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from test import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('NT_1504.pkl', 'r') as f_un:\n",
    "    NT_1504 = pickle.load(f_un)\n",
    "    \n",
    "with open('NT_1505.pkl', 'r') as g_un:\n",
    "    NT_1505 = pickle.load(g_un)\n",
    "    \n",
    "with open('NT_1506.pkl', 'r') as h_un:\n",
    "    NT_1506 = pickle.load(h_un)\n",
    "    \n",
    "with open('NT_1507.pkl', 'r') as k_un:\n",
    "    NT_1507 = pickle.load(k_un)\n",
    "    \n",
    "with open('NT_1508.pkl', 'r') as m_un:\n",
    "    NT_1508 = pickle.load(m_un)\n",
    "    \n",
    "with open('NT_1509.pkl', 'r') as n_un:\n",
    "    NT_1509 = pickle.load(n_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "128\n",
      "174\n",
      "125\n",
      "125\n",
      "167\n"
     ]
    }
   ],
   "source": [
    "print len(NT_1504[0])\n",
    "print len(NT_1504[1])\n",
    "print len(NT_1504[2])\n",
    "\n",
    "print len(NT_1505[0])\n",
    "print len(NT_1505[1])\n",
    "print len(NT_1505[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = NT_1502[0]\n",
    "# len(text)\n",
    "# text.extend(NT_1503[0])\n",
    "# len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "379\n",
      "504\n",
      "648\n",
      "788\n",
      "936\n",
      "1012\n"
     ]
    }
   ],
   "source": [
    "print len(text)\n",
    "text.extend(NT_1504[0])\n",
    "print len(text)\n",
    "text.extend(NT_1505[0])\n",
    "print len(text)\n",
    "text.extend(NT_1506[0])\n",
    "print len(text)\n",
    "text.extend(NT_1507[0])\n",
    "print len(text)\n",
    "text.extend(NT_1508[0])\n",
    "print len(text)\n",
    "text.extend(NT_1509[0])\n",
    "print len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_text = clean_pdf_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 51s, sys: 894 ms, total: 1min 52s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "tfidf_math = TfidfVectorizer(max_features=150, stop_words=math_stop(), \\\n",
    "                    ngram_range=(2, 2), decode_error='ignore')\n",
    "M = tfidf_math.fit_transform(clean_text)\n",
    "N=M.todense()\n",
    "\n",
    "# Dists=np.zeros((N.shape[0], N.shape[0]))\n",
    "# for ix in range(len(Dists)):\n",
    "#     for jx in range(len(Dists)):\n",
    "#         Dists[ix, jx]=cosine(N[ix], N[jx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive integer does divide exists unique\n",
      "\n",
      "\n",
      "elliptic curve rational points curve deﬁned\n",
      "\n",
      "\n",
      "riemann zeta error term functional equation\n",
      "\n",
      "\n",
      "exact sequence commutative diagram abelian variety\n",
      "\n",
      "\n",
      "number theory cambridge university analytic number\n",
      "\n",
      "\n",
      "erd os abelian groups 12 12\n",
      "\n",
      "\n",
      "continued fraction diophantine approximation lebesgue measure\n",
      "\n",
      "\n",
      "modular forms eisenstein series fourier coeﬃcients\n",
      "\n",
      "\n",
      "polynomial degree number solutions polynomials degree\n",
      "\n",
      "\n",
      "power series zeta values vector space\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf_math.get_feature_names()\n",
    "feature_names = [WordNetLemmatizer().lemmatize(word) for word in feature_names]\n",
    "nmf = NMF(n_components=10)\n",
    "nmf.fit(M)\n",
    "topics = []\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    topics.append((\" \".join([feature_names[i] for i in topic.argsort()[:-3 - 1:-1]])))\n",
    "for topic in topics:\n",
    "    print topic\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "practice = [clean_text[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "practice_vec = tfidf_math.transform(practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "practice_dense = practice_vec.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "practice_distances = [cosine(x,practice_dense) for x in N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: Wild ramification kinks\n",
      "\n",
      "Score:  -0.0\n",
      "\n",
      "\n",
      "\n",
      "Title: The Monsky-Washnitzer and the overconvergent realizations\n",
      "\n",
      "Score:  0.048\n",
      "\n",
      "\n",
      "\n",
      "Title: D-modules on rigid analytic spaces II: Kashiwara's equivalence\n",
      "\n",
      "Score:  0.054\n",
      "\n",
      "\n",
      "\n",
      "Title: On the strongly ambiguous classes of $k/Q(\\sqrt{-1})$ where $k=  Q(\\sqrt{2p_1p_2},\\sqrt{-1})$\n",
      "\n",
      "Score:  0.083\n",
      "\n",
      "\n",
      "\n",
      "Title: Integral $p$-adic Hodge theory - announcement\n",
      "\n",
      "Score:  0.278\n",
      "\n",
      "\n",
      "\n",
      "Title: Rankin--Eisenstein classes in Coleman families\n",
      "\n",
      "Score:  0.46\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score_indices = np.argsort(practice_distances)[:6]\n",
    "best_scores = [np.around(practice_distances[i],3) for i in best_score_indices]\n",
    "best_titles = [title_list[i] for i in best_score_indices]\n",
    "together = [x for x in zip(best_titles, best_scores)]\n",
    "for x, y in zip(best_titles, best_scores):\n",
    "    print x\n",
    "    print 'Score: ', y\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances = Dists[15]\n",
    "best_score_indices = np.argsort(distances)[1:6]\n",
    "best_scores = [np.around(distances[i],3) for i in best_score_indices]\n",
    "best_titles = [title_list[i] for i in best_score_indices]\n",
    "together = [x for x in zip(best_titles, best_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: A simple twisted relative trace formula\n",
      "\n",
      "Score:  0.243\n",
      "\n",
      "\n",
      "\n",
      "Title: Sato-Tate equidistribution for families of Hecke-Maass forms on  SL(n,R)/SO(n)\n",
      "\n",
      "Score:  0.296\n",
      "\n",
      "\n",
      "\n",
      "Title: Local bounds for $L^p$ norms of Maass forms in the level aspect\n",
      "\n",
      "Score:  0.318\n",
      "\n",
      "\n",
      "\n",
      "Title: Selberg Formula for Cofinite Groups and the Roelke Conjecture\n",
      "\n",
      "Score:  0.399\n",
      "\n",
      "\n",
      "\n",
      "Title: Sums of Kloosterman sums in arithmetic progressions, and the error term  in the dispersion method\n",
      "\n",
      "Score:  0.425\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(best_titles, best_scores):\n",
    "    print x\n",
    "    print 'Score: ', y\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://lanl.arxiv.org/pdf/1508.00111'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NT_1508[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('NT_1508_new.pkl') as f:\n",
    "    new_August = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_August)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles = []\n",
    "for triple in new_August:\n",
    "    titles.append(triple[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = [1,2,3]\n",
    "J = [4,5,6]\n",
    "K = ['a', 'b', 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4, 'a'), (2, 5, 'b'), (3, 6, 'c')]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(H,J,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "from test import *\n",
    "\n",
    "#user_url = input('Please enter a pdf url: ')\n",
    "\n",
    "dates = []\n",
    "for year in ['15','14','13','12']:\n",
    "    for i in range(12,0, -1):\n",
    "        if len(str(i)) == 1:\n",
    "            dates.append(year+'0'+str(i))\n",
    "        else:\n",
    "            dates.append(year+str(i))\n",
    "good_dates = dates[3:]\n",
    "\n",
    "front = 'http://lanl.arxiv.org/list/math.NT/'\n",
    "end = '?show=250'\n",
    "NT_urls = [front+x+end for x in good_dates]\n",
    "\n",
    "\n",
    "\n",
    "NT_names = ['NT_'+date+'.pkl' for date in good_dates]\n",
    "\n",
    "NT_names_new = ['NT_'+date+'_new.pkl' for date in good_dates]\n",
    "\n",
    "small_NT_urls = NT_urls[:9]\n",
    "small_NT_names = NT_names_new[:9]\n",
    "small_NT_tags = [x[:7] for x in small_NT_names]\n",
    "\n",
    "\n",
    "    \n",
    "with open('NT_1501_new.pkl', 'r') as k_un:\n",
    "    NT_1501 = pickle.load(k_un)\n",
    "    \n",
    "with open('NT_1502_new.pkl', 'r') as m_un:\n",
    "    NT_1502 = pickle.load(m_un)\n",
    "    \n",
    "with open('NT_1503_new.pkl', 'r') as n_un:\n",
    "    NT_1503 = pickle.load(n_un)\n",
    "\n",
    "with open('NT_1504_new.pkl', 'r') as f_un:\n",
    "    NT_1504 = pickle.load(f_un)\n",
    "    \n",
    "with open('NT_1505_new.pkl', 'r') as g_un:\n",
    "    NT_1505 = pickle.load(g_un)\n",
    "    \n",
    "with open('NT_1506_new.pkl', 'r') as h_un:\n",
    "    NT_1506 = pickle.load(h_un)\n",
    "    \n",
    "with open('NT_1507_new.pkl', 'r') as k_un:\n",
    "    NT_1507 = pickle.load(k_un)\n",
    "    \n",
    "with open('NT_1508_new.pkl', 'r') as m_un:\n",
    "    NT_1508 = pickle.load(m_un)\n",
    "    \n",
    "with open('NT_1509_new.pkl', 'r') as n_un:\n",
    "    NT_1509 = pickle.load(n_un)\n",
    "\n",
    "Tags = [NT_1501, NT_1502, NT_1503, NT_1504, NT_1505, NT_1506, NT_1507, NT_1508, NT_1509]\n",
    "    \n",
    "text = []\n",
    "title_list = []\n",
    "urls = []\n",
    "for tag in Tags:\n",
    "    for triple in tag:\n",
    "        text.append(triple[0])\n",
    "        urls.append(triple[1])\n",
    "        title_list.append(triple[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = clean_pdf_text(text)\n",
    "\n",
    "tfidf_math = TfidfVectorizer(max_features=150, stop_words=math_stop(), \\\n",
    "                    ngram_range=(2, 2), decode_error='ignore')\n",
    "M = tfidf_math.fit_transform(text)\n",
    "\n",
    "N=M.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_text = [parsePDF('http://lanl.arxiv.org/pdf/1407.0054.pdf')]\n",
    "user_text = clean_pdf_text(user_text)\n",
    "user_vec = tfidf_math.transform(user_text)\n",
    "user_dense = user_vec.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closest papers in the past year to yours are: \n",
      "\n",
      "\n",
      "\n",
      "Title: Short intervals asymptotic formulae for binary problems with primes and  powers, II: density $1$\n",
      "\n",
      "Score:  0.244\n",
      "URL:  http://lanl.arxiv.org/pdf/1504.04711\n",
      "\n",
      "\n",
      "\n",
      "Title: Some identities of symmetry for q-Bernoulli polynomials under symmetric  group of degree n\n",
      "\n",
      "Score:  0.274\n",
      "URL:  http://lanl.arxiv.org/pdf/1504.05549\n",
      "\n",
      "\n",
      "\n",
      "Title: Moments of averages of generalized Ramanujan sums\n",
      "\n",
      "Score:  0.275\n",
      "URL:  http://lanl.arxiv.org/pdf/1508.01760\n",
      "\n",
      "\n",
      "\n",
      "Title: A relative trace formula for a compact Riemann surface\n",
      "\n",
      "Score:  0.291\n",
      "URL:  http://lanl.arxiv.org/pdf/1504.05718\n",
      "\n",
      "\n",
      "\n",
      "Title: Bilinear forms with $GL_3$ Kloosterman sums and the spectral large sieve\n",
      "\n",
      "Score:  0.306\n",
      "URL:  http://lanl.arxiv.org/pdf/1505.02150\n",
      "\n",
      "\n",
      "\n",
      "Title: Non-vanishing of Dirichlet L-functions in Galois orbits\n",
      "\n",
      "Score:  0.322\n",
      "URL:  http://lanl.arxiv.org/pdf/1507.00111\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distances = [cosine(x, user_dense) for x in N]\n",
    "best_score_indices = np.argsort(distances)[:6]\n",
    "best_scores = [np.around(distances[i],3) for i in best_score_indices]\n",
    "best_titles = [title_list[i] for i in best_score_indices]\n",
    "best_urls = [urls[i] for i in best_score_indices]\n",
    "\n",
    "print 'The closest papers in the past year to yours are: '\n",
    "print '\\n'\n",
    "for x, y, z in zip(best_titles, best_scores, best_urls):\n",
    "    print x\n",
    "    print 'Score: ', y\n",
    "    print 'URL: ', z\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The major NMF topics from the corpus are: \n",
      "\n",
      "\n",
      "positive integer congruent modulo does divide exists unique loss generality\n",
      "\n",
      "\n",
      "elliptic curve rational points curve deﬁned good reduction rational point\n",
      "\n",
      "\n",
      "error term riemann zeta functional equation 12 12 asymptotic formula\n",
      "\n",
      "\n",
      "exact sequence abelian variety commutative diagram abelian varieties base change\n",
      "\n",
      "\n",
      "modular forms eisenstein series fourier coeﬃcients cusp forms holomorphic modular\n",
      "\n",
      "\n",
      "polynomial degree polynomials degree number solutions lower bounds minimal polynomial\n",
      "\n",
      "\n",
      "continued fraction diophantine approximation lebesgue measure algebraic number loss generality\n",
      "\n",
      "\n",
      "power series zeta values vector space 19 18 explicit formula\n",
      "\n",
      "\n",
      "number theory square free algebraic number analytic number cambridge university\n",
      "\n",
      "\n",
      "erd os loss generality abelian groups lower bounds error term\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf_math.get_feature_names()\n",
    "feature_names = [WordNetLemmatizer().lemmatize(word) for word in feature_names]\n",
    "nmf = NMF(n_components=10)\n",
    "nmf.fit(M)\n",
    "topics = []\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    topics.append((\" \".join([feature_names[i] for i in topic.argsort()[:-5 - 1:-1]])))\n",
    "\n",
    "print 'The major NMF topics from the corpus are: '\n",
    "print '\\n'\n",
    "for topic in topics:\n",
    "    print topic\n",
    "    print '\\n'\n",
    "\n",
    "\n",
    "# countvec = CountVectorizer(decode_error='ignore', stop_words='english', max_features=5000, ngram_range=(2,2))\n",
    "# CV = countvec.fit_transform(text)\n",
    "# vocab=tuple(countvec.vocabulary_)\n",
    "# lda_model = lda.LDA(n_topics=10, n_iter=1500)\n",
    "# lda_model.fit(CV)\n",
    "\n",
    "# topic_word = lda_model.topic_word_  # model.components_ also works\n",
    "# n_top_words = 8\n",
    "# topic_words = []\n",
    "# for i, topic_dist in enumerate(topic_word):\n",
    "#     topic_words.append(np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1])\n",
    "\n",
    "# print 'The LDA topics are: '\n",
    "# for i in range(len(topic_words)):\n",
    "#     print ' '.join(topic_words[i])\n",
    "#     print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "countvec = CountVectorizer(decode_error='ignore', stop_words='english', max_features=5000, ngram_range=(2,2))\n",
    "CV = countvec.fit_transform(text)\n",
    "vocab=tuple(countvec.vocabulary_)\n",
    "lda_model = lda.LDA(n_topics=10, n_iter=1500)\n",
    "lda_model.fit(CV)\n",
    "\n",
    "topic_word = lda_model.topic_word_  # model.components_ also works\n",
    "n_top_words = 8\n",
    "topic_words = []\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words.append(np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1])\n",
    "\n",
    "print 'The LDA topics are: '\n",
    "for i in range(len(topic_words)):\n",
    "    print ' '.join(topic_words[i])\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
