{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from test import *\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('NT_1504.pkl', 'r') as f_un:\n",
    "    NT_1504 = pickle.load(f_un)\n",
    "    \n",
    "with open('NT_1505.pkl', 'r') as g_un:\n",
    "    NT_1505 = pickle.load(g_un)\n",
    "    \n",
    "with open('NT_1506.pkl', 'r') as h_un:\n",
    "    NT_1506 = pickle.load(h_un)\n",
    "    \n",
    "with open('NT_1507.pkl', 'r') as k_un:\n",
    "    NT_1507 = pickle.load(k_un)\n",
    "    \n",
    "with open('NT_1508.pkl', 'r') as m_un:\n",
    "    NT_1508 = pickle.load(m_un)\n",
    "    \n",
    "with open('NT_1509.pkl', 'r') as n_un:\n",
    "    NT_1509 = pickle.load(n_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "128\n",
      "174\n",
      "125\n",
      "125\n",
      "167\n"
     ]
    }
   ],
   "source": [
    "print len(NT_1504[0])\n",
    "print len(NT_1504[1])\n",
    "print len(NT_1504[2])\n",
    "\n",
    "print len(NT_1505[0])\n",
    "print len(NT_1505[1])\n",
    "print len(NT_1505[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# text = NT_1502[0]\n",
    "# len(text)\n",
    "# text.extend(NT_1503[0])\n",
    "# len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "379\n",
      "504\n",
      "648\n",
      "788\n",
      "936\n",
      "1012\n"
     ]
    }
   ],
   "source": [
    "print len(text)\n",
    "text.extend(NT_1504[0])\n",
    "print len(text)\n",
    "text.extend(NT_1505[0])\n",
    "print len(text)\n",
    "text.extend(NT_1506[0])\n",
    "print len(text)\n",
    "text.extend(NT_1507[0])\n",
    "print len(text)\n",
    "text.extend(NT_1508[0])\n",
    "print len(text)\n",
    "text.extend(NT_1509[0])\n",
    "print len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_text = clean_pdf_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 51s, sys: 894 ms, total: 1min 52s\n",
      "Wall time: 1min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "tfidf_math = TfidfVectorizer(max_features=150, stop_words=math_stop(), \\\n",
    "                    ngram_range=(2, 2), decode_error='ignore')\n",
    "M = tfidf_math.fit_transform(clean_text)\n",
    "N=M.todense()\n",
    "\n",
    "# Dists=np.zeros((N.shape[0], N.shape[0]))\n",
    "# for ix in range(len(Dists)):\n",
    "#     for jx in range(len(Dists)):\n",
    "#         Dists[ix, jx]=cosine(N[ix], N[jx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive integer does divide exists unique\n",
      "\n",
      "\n",
      "elliptic curve rational points curve deﬁned\n",
      "\n",
      "\n",
      "riemann zeta error term functional equation\n",
      "\n",
      "\n",
      "exact sequence commutative diagram abelian variety\n",
      "\n",
      "\n",
      "number theory cambridge university analytic number\n",
      "\n",
      "\n",
      "erd os abelian groups 12 12\n",
      "\n",
      "\n",
      "continued fraction diophantine approximation lebesgue measure\n",
      "\n",
      "\n",
      "modular forms eisenstein series fourier coeﬃcients\n",
      "\n",
      "\n",
      "polynomial degree number solutions polynomials degree\n",
      "\n",
      "\n",
      "power series zeta values vector space\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf_math.get_feature_names()\n",
    "feature_names = [WordNetLemmatizer().lemmatize(word) for word in feature_names]\n",
    "nmf = NMF(n_components=10)\n",
    "nmf.fit(M)\n",
    "topics = []\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    topics.append((\" \".join([feature_names[i] for i in topic.argsort()[:-3 - 1:-1]])))\n",
    "for topic in topics:\n",
    "    print topic\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "practice = [clean_text[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "practice_vec = tfidf_math.transform(practice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "practice_dense = practice_vec.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "practice_distances = [cosine(x,practice_dense) for x in N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: Wild ramification kinks\n",
      "\n",
      "Score:  -0.0\n",
      "\n",
      "\n",
      "\n",
      "Title: The Monsky-Washnitzer and the overconvergent realizations\n",
      "\n",
      "Score:  0.048\n",
      "\n",
      "\n",
      "\n",
      "Title: D-modules on rigid analytic spaces II: Kashiwara's equivalence\n",
      "\n",
      "Score:  0.054\n",
      "\n",
      "\n",
      "\n",
      "Title: On the strongly ambiguous classes of $k/Q(\\sqrt{-1})$ where $k=  Q(\\sqrt{2p_1p_2},\\sqrt{-1})$\n",
      "\n",
      "Score:  0.083\n",
      "\n",
      "\n",
      "\n",
      "Title: Integral $p$-adic Hodge theory - announcement\n",
      "\n",
      "Score:  0.278\n",
      "\n",
      "\n",
      "\n",
      "Title: Rankin--Eisenstein classes in Coleman families\n",
      "\n",
      "Score:  0.46\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score_indices = np.argsort(practice_distances)[:6]\n",
    "best_scores = [np.around(practice_distances[i],3) for i in best_score_indices]\n",
    "best_titles = [title_list[i] for i in best_score_indices]\n",
    "together = [x for x in zip(best_titles, best_scores)]\n",
    "for x, y in zip(best_titles, best_scores):\n",
    "    print x\n",
    "    print 'Score: ', y\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "distances = Dists[15]\n",
    "best_score_indices = np.argsort(distances)[1:6]\n",
    "best_scores = [np.around(distances[i],3) for i in best_score_indices]\n",
    "best_titles = [title_list[i] for i in best_score_indices]\n",
    "together = [x for x in zip(best_titles, best_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Title: A simple twisted relative trace formula\n",
      "\n",
      "Score:  0.243\n",
      "\n",
      "\n",
      "\n",
      "Title: Sato-Tate equidistribution for families of Hecke-Maass forms on  SL(n,R)/SO(n)\n",
      "\n",
      "Score:  0.296\n",
      "\n",
      "\n",
      "\n",
      "Title: Local bounds for $L^p$ norms of Maass forms in the level aspect\n",
      "\n",
      "Score:  0.318\n",
      "\n",
      "\n",
      "\n",
      "Title: Selberg Formula for Cofinite Groups and the Roelke Conjecture\n",
      "\n",
      "Score:  0.399\n",
      "\n",
      "\n",
      "\n",
      "Title: Sums of Kloosterman sums in arithmetic progressions, and the error term  in the dispersion method\n",
      "\n",
      "Score:  0.425\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(best_titles, best_scores):\n",
    "    print x\n",
    "    print 'Score: ', y\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://lanl.arxiv.org/pdf/1508.00111'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NT_1508[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('NT_1508_new.pkl') as f:\n",
    "    new_August = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_August)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titles = []\n",
    "for triple in new_August:\n",
    "    titles.append(triple[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "H = [1,2,3]\n",
    "J = [4,5,6]\n",
    "K = ['a', 'b', 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4, 'a'), (2, 5, 'b'), (3, 6, 'c')]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(H,J,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "from test import *\n",
    "\n",
    "#user_url = input('Please enter a pdf url: ')\n",
    "\n",
    "# dates = []\n",
    "# for year in ['15','14','13','12']:\n",
    "#     for i in range(12,0, -1):\n",
    "#         if len(str(i)) == 1:\n",
    "#             dates.append(year+'0'+str(i))\n",
    "#         else:\n",
    "#             dates.append(year+str(i))\n",
    "# good_dates = dates[3:]\n",
    "\n",
    "# front = 'http://lanl.arxiv.org/list/math.NT/'\n",
    "# end = '?show=250'\n",
    "# NT_urls = [front+x+end for x in good_dates]\n",
    "\n",
    "\n",
    "\n",
    "# NT_names = ['NT_'+date+'.pkl' for date in good_dates]\n",
    "\n",
    "# NT_names_new = ['NT_'+date+'_new.pkl' for date in good_dates]\n",
    "\n",
    "# small_NT_urls = NT_urls[:9]\n",
    "# small_NT_names = NT_names_new[:9]\n",
    "# small_NT_tags = [x[:7] for x in small_NT_names]\n",
    "\n",
    "\n",
    "    \n",
    "with open('NT_1501_new.pkl', 'r') as k_un:\n",
    "    NT_1501 = pickle.load(k_un)\n",
    "    \n",
    "with open('NT_1502_new.pkl', 'r') as m_un:\n",
    "    NT_1502 = pickle.load(m_un)\n",
    "    \n",
    "with open('NT_1503_new.pkl', 'r') as n_un:\n",
    "    NT_1503 = pickle.load(n_un)\n",
    "\n",
    "with open('NT_1504_new.pkl', 'r') as f_un:\n",
    "    NT_1504 = pickle.load(f_un)\n",
    "    \n",
    "with open('NT_1505_new.pkl', 'r') as g_un:\n",
    "    NT_1505 = pickle.load(g_un)\n",
    "    \n",
    "with open('NT_1506_new.pkl', 'r') as h_un:\n",
    "    NT_1506 = pickle.load(h_un)\n",
    "    \n",
    "with open('NT_1507_new.pkl', 'r') as k_un:\n",
    "    NT_1507 = pickle.load(k_un)\n",
    "    \n",
    "with open('NT_1508_new.pkl', 'r') as m_un:\n",
    "    NT_1508 = pickle.load(m_un)\n",
    "    \n",
    "with open('NT_1509_new.pkl', 'r') as n_un:\n",
    "    NT_1509 = pickle.load(n_un)\n",
    "\n",
    "Tags = [NT_1501, NT_1502, NT_1503, NT_1504, NT_1505, NT_1506, NT_1507, NT_1508, NT_1509]\n",
    "    \n",
    "text = []\n",
    "title_list = []\n",
    "urls = []\n",
    "for tag in Tags:\n",
    "    for triple in tag:\n",
    "        text.append(triple[0])\n",
    "        urls.append(triple[1])\n",
    "        title_list.append(triple[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 25s, sys: 1.1 s, total: 2min 26s\n",
      "Wall time: 2min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = clean_pdf_text(text)\n",
    "\n",
    "tfidf_NT = TfidfVectorizer(max_features=150, stop_words=math_stop(), \\\n",
    "                    ngram_range=(2, 2), decode_error='ignore')\n",
    "M = tfidf_NT.fit_transform(text)\n",
    "\n",
    "N=M.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('NT_sim_model_and_fitted_matrix.pkl', 'w') as f:\n",
    "    pickle.dump((tfidf_NT, M),f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('NT_titles_and_urls.pkl', 'w') as f:\n",
    "    pickle.dump((title_list, urls), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_text = [parsePDF('http://www.folgerdigitaltexts.org/PDF/Rom.pdf')]\n",
    "user_text = clean_pdf_text(user_text)\n",
    "user_vec = tfidf_math.transform(user_text)\n",
    "user_dense = user_vec.todense()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_dense.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The closest papers in the past year to yours are: \n",
      "\n",
      "\n",
      "\n",
      "Title: A Proof for the Erdós-Ulam Problem assuming Bombieri-Lang Conjecture\n",
      "\n",
      "Score:  nan\n",
      "URL:  http://lanl.arxiv.org/pdf/1501.00159\n",
      "\n",
      "\n",
      "\n",
      "Title: Linnik's Theorem for Sato-Tate Laws on Elliptic Curves with Complex  Multiplication\n",
      "\n",
      "Score:  nan\n",
      "URL:  http://lanl.arxiv.org/pdf/1506.09170\n",
      "\n",
      "\n",
      "\n",
      "Title: Nonabelian Fourier transforms for spherical representations\n",
      "\n",
      "Score:  nan\n",
      "URL:  http://lanl.arxiv.org/pdf/1506.09128\n",
      "\n",
      "\n",
      "\n",
      "Title: Elliptic multiple zeta values, Grothendieck-Teichmüller and mould  theory\n",
      "\n",
      "Score:  nan\n",
      "URL:  http://lanl.arxiv.org/pdf/1506.09050\n",
      "\n",
      "\n",
      "\n",
      "Title: Diophantine approximation on manifolds and the distribution of rational  points: contributions to the convergence theory\n",
      "\n",
      "Score:  nan\n",
      "URL:  http://lanl.arxiv.org/pdf/1506.09049\n",
      "\n",
      "\n",
      "\n",
      "Title: Beyond Endoscopy via the trace formula - II: Asymptotic expansions of  Fourier transforms and bounds towards the Ramanujan conjecture\n",
      "\n",
      "Score:  nan\n",
      "URL:  http://lanl.arxiv.org/pdf/1506.08911\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distances = [cosine(x, user_dense) for x in N]\n",
    "best_score_indices = np.argsort(distances)[:6]\n",
    "best_scores = [np.around(distances[i],3) for i in best_score_indices]\n",
    "best_titles = [title_list[i] for i in best_score_indices]\n",
    "best_urls = [urls[i] for i in best_score_indices]\n",
    "\n",
    "print 'The closest papers in the past year to yours are: '\n",
    "print '\\n'\n",
    "for x, y, z in zip(best_titles, best_scores, best_urls):\n",
    "    print x\n",
    "    print 'Score: ', y\n",
    "    print 'URL: ', z\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The major NMF topics from the corpus are: \n",
      "\n",
      "\n",
      "positive integer congruent modulo does divide exists unique loss generality\n",
      "\n",
      "\n",
      "elliptic curve rational points curve deﬁned good reduction rational point\n",
      "\n",
      "\n",
      "error term riemann zeta functional equation 12 12 asymptotic formula\n",
      "\n",
      "\n",
      "exact sequence abelian variety commutative diagram abelian varieties base change\n",
      "\n",
      "\n",
      "modular forms eisenstein series fourier coeﬃcients cusp forms holomorphic modular\n",
      "\n",
      "\n",
      "polynomial degree polynomials degree number solutions lower bounds minimal polynomial\n",
      "\n",
      "\n",
      "continued fraction diophantine approximation lebesgue measure algebraic number loss generality\n",
      "\n",
      "\n",
      "power series zeta values vector space 19 18 explicit formula\n",
      "\n",
      "\n",
      "number theory square free algebraic number analytic number cambridge university\n",
      "\n",
      "\n",
      "erd os loss generality abelian groups lower bounds error term\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_names = tfidf_math.get_feature_names()\n",
    "feature_names = [WordNetLemmatizer().lemmatize(word) for word in feature_names]\n",
    "nmf = NMF(n_components=10)\n",
    "nmf.fit(M)\n",
    "topics = []\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    topics.append((\" \".join([feature_names[i] for i in topic.argsort()[:-5 - 1:-1]])))\n",
    "\n",
    "print 'The major NMF topics from the corpus are: '\n",
    "print '\\n'\n",
    "for topic in topics:\n",
    "    print topic\n",
    "    print '\\n'\n",
    "\n",
    "\n",
    "# countvec = CountVectorizer(decode_error='ignore', stop_words='english', max_features=5000, ngram_range=(2,2))\n",
    "# CV = countvec.fit_transform(text)\n",
    "# vocab=tuple(countvec.vocabulary_)\n",
    "# lda_model = lda.LDA(n_topics=10, n_iter=1500)\n",
    "# lda_model.fit(CV)\n",
    "\n",
    "# topic_word = lda_model.topic_word_  # model.components_ also works\n",
    "# n_top_words = 8\n",
    "# topic_words = []\n",
    "# for i, topic_dist in enumerate(topic_word):\n",
    "#     topic_words.append(np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1])\n",
    "\n",
    "# print 'The LDA topics are: '\n",
    "# for i in range(len(topic_words)):\n",
    "#     print ' '.join(topic_words[i])\n",
    "#     print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:lda:all zero row in document-term matrix found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The LDA topics are: \n",
      "does depend cusp forms hecke operators th eor good reduction semi simple power series\n",
      "\n",
      "\n",
      "abelian varieties maximal ideal repr esentations constant term explicit formula number solutions canonical isomorphism\n",
      "\n",
      "\n",
      "square free absolutely convergent canonical isomorphism linear combination polynomials degree absolute value modular forms\n",
      "\n",
      "\n",
      "dirichlet series short exact vector space gives rise forms weight characteristic polynomial automorphic forms\n",
      "\n",
      "\n",
      "exact sequence modular forms algebraic number compact open erd os eor eme quadratic forms\n",
      "\n",
      "\n",
      "parabolic subgroup algebraically closed mean value algebraic closure sous groupe elliptic curve vari et\n",
      "\n",
      "\n",
      "continued fraction rational point zeta functions automorphic representation special values lecture notes does depend\n",
      "\n",
      "\n",
      "constant depending number theory moduli space 19 18 modular forms riemann hypothesis uniquely determined\n",
      "\n",
      "\n",
      "galois representations 12 12 rankin selberg cambridge university reduction modulo siegel modular commutative diagram\n",
      "\n",
      "\n",
      "galois representation local langlands polynomial degree haar measure free rank rational points polynomials degree\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "countvec = CountVectorizer(decode_error='ignore', stop_words=math_stop(), max_features=100, ngram_range=(2,2))\n",
    "CV = countvec.fit_transform(text)\n",
    "vocab=tuple(countvec.vocabulary_)\n",
    "lda_model = lda.LDA(n_topics=10, n_iter=1500)\n",
    "lda_model.fit(CV)\n",
    "\n",
    "topic_word = lda_model.topic_word_  # model.components_ also works\n",
    "n_top_words = 8\n",
    "topic_words = []\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    topic_words.append(np.array(vocab)[np.argsort(topic_dist)][:-n_top_words:-1])\n",
    "\n",
    "print 'The LDA topics are: '\n",
    "for i in range(len(topic_words)):\n",
    "    print ' '.join(topic_words[i])\n",
    "    print '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.87836049e-07,   2.87836049e-07,   2.87836049e-07, ...,\n",
       "          1.41068447e-03,   2.87836049e-07,   2.87836049e-07],\n",
       "       [  2.58686593e-03,   2.87397615e-07,   2.87397615e-07, ...,\n",
       "          2.87397615e-07,   2.87397615e-07,   2.87397615e-07],\n",
       "       [  2.08554923e-07,   2.08554923e-07,   2.08554923e-07, ...,\n",
       "          2.08554923e-07,   2.08554923e-07,   1.87907986e-04],\n",
       "       ..., \n",
       "       [  1.00728874e-02,   1.16442690e-03,   2.53081264e-07, ...,\n",
       "          2.53081264e-07,   2.53081264e-07,   2.53081264e-07],\n",
       "       [  8.07272401e-04,   2.24180061e-07,   1.12314211e-04, ...,\n",
       "          2.24180061e-07,   2.24180061e-07,   2.24180061e-07],\n",
       "       [  4.76326569e-07,   4.76326569e-07,   4.76326569e-07, ...,\n",
       "          4.81089835e-05,   4.76326569e-07,   4.76326569e-07]])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
